K-Nearest Neighbors (K-NN) Classification (Social Network Ads)
ğŸ“Œ Overview

This project demonstrates K-Nearest Neighbors (K-NN), a simple and intuitive classification algorithm.

The dataset (Social_Network_Ads.csv) contains:

Age

Estimated Salary

Purchased â†’ whether a user bought the product (0 = No, 1 = Yes).

The goal is to train a model that predicts if a user will purchase a product based on their age and salary by checking the closest data points (neighbors).

ğŸš€ Why Itâ€™s Important

Classification tasks â†’ K-NN is widely used for category prediction.

Easy to understand â†’ It classifies based on the majority vote of the nearest neighbors.

Preprocessing â†’ Feature scaling ensures distances are measured correctly.

Visualization â†’ Decision boundary plots help us see how the algorithm separates the two classes.

âš™ï¸ What the Code Does

Import libraries â†’ numpy, pandas, matplotlib for data handling and visualization.

Load the dataset (Social_Network_Ads.csv) â†’ Extract features (X) and target (y).

Split the dataset â†’ Training (75%) and Testing (25%).

Apply Feature Scaling â†’ Normalize values for correct distance measurement.

Train the K-NN classifier â†’ Using n_neighbors=5.

Make predictions â†’ For a new user and on the test set.

Evaluate the model â†’ Using Confusion Matrix and Accuracy Score.

Visualize decision boundaries â†’ For both training and test sets.
